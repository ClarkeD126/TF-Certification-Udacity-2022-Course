{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\clark\\Desktop\\Tech\\Tf\\MNIST fashion with CNN.ipynb Cell 1\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/clark/Desktop/Tech/Tf/MNIST%20fashion%20with%20CNN.ipynb#W0sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/clark/Desktop/Tech/Tf/MNIST%20fashion%20with%20CNN.ipynb#W0sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/clark/Desktop/Tech/Tf/MNIST%20fashion%20with%20CNN.ipynb#W0sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/clark/Desktop/Tech/Tf/MNIST%20fashion%20with%20CNN.ipynb#W0sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\data_sci\\lib\\site-packages\\tensorflow\\__init__.py:37\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39msys\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39m_sys\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtyping\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39m_typing\u001b[39;00m\n\u001b[1;32m---> 37\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtools\u001b[39;00m \u001b[39mimport\u001b[39;00m module_util \u001b[39mas\u001b[39;00m _module_util\n\u001b[0;32m     38\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutil\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlazy_loader\u001b[39;00m \u001b[39mimport\u001b[39;00m LazyLoader \u001b[39mas\u001b[39;00m _LazyLoader\n\u001b[0;32m     40\u001b[0m \u001b[39m# Make sure code inside the TensorFlow codebase can use tf2.enabled() at import.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\data_sci\\lib\\site-packages\\tensorflow\\python\\__init__.py:143\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcompiler\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mxla\u001b[39;00m \u001b[39mimport\u001b[39;00m xla\n\u001b[0;32m    142\u001b[0m \u001b[39m# MLIR APIs.\u001b[39;00m\n\u001b[1;32m--> 143\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcompiler\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmlir\u001b[39;00m \u001b[39mimport\u001b[39;00m mlir\n\u001b[0;32m    145\u001b[0m \u001b[39m# Structs (aka extension types)\u001b[39;00m\n\u001b[0;32m    146\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mframework\u001b[39;00m \u001b[39mimport\u001b[39;00m extension_type \u001b[39mas\u001b[39;00m _extension_type\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\data_sci\\lib\\site-packages\\tensorflow\\python\\compiler\\mlir\\mlir.py:17\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Copyright 2019 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[39m# limitations under the License.\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[39m# =============================================================================\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[39m\"\"\"mlir is an experimental library that provides support APIs for MLIR.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m \u001b[39mimport\u001b[39;00m pywrap_mlir\n\u001b[0;32m     18\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutil\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtf_export\u001b[39;00m \u001b[39mimport\u001b[39;00m tf_export\n\u001b[0;32m     21\u001b[0m \u001b[39m@tf_export\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mmlir.experimental.convert_graph_def\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     22\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconvert_graph_def\u001b[39m(graph_def,\n\u001b[0;32m     23\u001b[0m                       pass_pipeline\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtf-standard-pipeline\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m     24\u001b[0m                       show_debug_info\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\data_sci\\lib\\site-packages\\tensorflow\\python\\pywrap_mlir.py:20\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m \u001b[39mimport\u001b[39;00m pywrap_tensorflow\n\u001b[0;32m     19\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39meager\u001b[39;00m \u001b[39mimport\u001b[39;00m context\n\u001b[1;32m---> 20\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_pywrap_mlir\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[0;32m     23\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mimport_graphdef\u001b[39m(graphdef,\n\u001b[0;32m     24\u001b[0m                     pass_pipeline,\n\u001b[0;32m     25\u001b[0m                     show_debug_info,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     28\u001b[0m                     input_data_shapes\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m     29\u001b[0m                     output_names\u001b[39m=\u001b[39m[]):\n\u001b[0;32m     30\u001b[0m   \u001b[39mif\u001b[39;00m input_names \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow_datasets as tfds\n",
    "import math as m \n",
    "dataset, meta = tfds.load('fashion_mnist', as_supervised=True, with_info=True)\n",
    "\n",
    "train_data, test_data = dataset['train'], dataset['test']\n",
    "\n",
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal',      'Shirt',   'Sneaker',  'Bag',   'Ankle boot']\n",
    "\n",
    "num_train_examples = meta.splits['train'].num_examples\n",
    "num_test_examples = meta.splits['test'].num_examples\n",
    "\n",
    "print(\"Train: {} \\n Test: {}\".format(num_train_examples, num_test_examples))\n",
    "\n",
    "def normalize(data, labels):\n",
    "    data=tf.cast(data, tf.float32)\n",
    "    data /= 255\n",
    "    return data, labels\n",
    "\n",
    "train_data, test_data = train_data.map(normalize), test_data.map(normalize)\n",
    "train_data, test_data = train_data.cache(), test_data.cache()\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3,3), padding='same', activation='relu',\n",
    "                            input_shape=(28,28,1)),\n",
    "    tf.keras.layers.MaxPool2D((2,2), strides=2),\n",
    "    tf.keras.layers.Conv2D(64, (3,3), padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D((2,2), strides=2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', \n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "\n",
    "batch=42\n",
    "train_data = train_data.cache().repeat().shuffle(num_train_examples).batch(batch)\n",
    "test_data = test_data.cache().repeat().batch(batch)\n",
    "\n",
    "model.fit(train_data, epochs=10, steps_per_epoch=m.ceil(num_train_examples/batch), verbose=2)\n",
    "\n",
    "loss, test_acc = model.evaluate(test_data, steps=m.ceil(num_test_examples/32), verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('data_sci')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d63963d85136318b9f49e6cdc246fa710d8d44bb87bdde67353211b53794eecd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
